#!/usr/bin/env python3
"""GPTçµ±åˆãƒ†ã‚¹ãƒˆ - å®Ÿéš›ã®GPTãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸå‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""

import asyncio
import os
import sys
import json
import urllib.request
from typing import Optional
from dataclasses import dataclass

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from llm_qualitative_sort import (
    QualitativeSorter,
    MemoryCache,
    EventType,
)
from llm_qualitative_sort.providers.base import LLMProvider
from llm_qualitative_sort.models import ComparisonResult


class OpenAIProviderSync(LLMProvider):
    """åŒæœŸHTTPã‚’ä½¿ç”¨ã—ãŸOpenAIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰

    Note: aiohttp ã®DNSè§£æ±ºã«å•é¡ŒãŒã‚ã‚‹ç’°å¢ƒå‘ã‘ã®ãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè£…
    """

    DEFAULT_BASE_URL = "https://api.openai.com/v1"
    DEFAULT_MODEL = "gpt-4o-mini"

    def __init__(
        self,
        api_key: str,
        base_url: str | None = None,
        model: str | None = None
    ):
        super().__init__(
            api_key=api_key,
            base_url=base_url or self.DEFAULT_BASE_URL,
            model=model or self.DEFAULT_MODEL
        )

    async def compare(
        self,
        item_a: str,
        item_b: str,
        criteria: str
    ) -> ComparisonResult:
        """Compare two items using OpenAI API."""
        prompt = self._build_prompt(item_a, item_b, criteria)

        # åŒæœŸçš„ãªHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã§å®Ÿè¡Œï¼‰
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None, self._sync_request, prompt
        )

    def _sync_request(self, prompt: str) -> ComparisonResult:
        """åŒæœŸçš„ãªHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        url = f"{self.base_url}/chat/completions"

        payload = json.dumps({
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0,
        }).encode('utf-8')

        req = urllib.request.Request(
            url,
            data=payload,
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
            },
        )

        try:
            with urllib.request.urlopen(req, timeout=60) as response:
                raw_response = json.loads(response.read())
                return self._parse_response(raw_response)
        except urllib.error.HTTPError as e:
            error_body = e.read().decode('utf-8')
            return ComparisonResult(
                winner=None,
                reasoning=f"API error: {e.code} - {error_body}",
                raw_response={"error": error_body}
            )
        except Exception as e:
            return ComparisonResult(
                winner=None,
                reasoning=f"Request error: {e}",
                raw_response={"error": str(e)}
            )

    def _parse_response(self, raw_response: dict) -> ComparisonResult:
        """Parse OpenAI response into ComparisonResult."""
        try:
            content = raw_response["choices"][0]["message"]["content"]
            # Try to parse JSON from response
            data = json.loads(content)
            winner = data.get("winner")
            reasoning = data.get("reasoning", "")

            if winner not in ("A", "B"):
                return ComparisonResult(
                    winner=None,
                    reasoning=f"Invalid winner: {winner}",
                    raw_response=raw_response
                )

            return ComparisonResult(
                winner=winner,
                reasoning=reasoning,
                raw_response=raw_response
            )
        except (KeyError, json.JSONDecodeError) as e:
            return ComparisonResult(
                winner=None,
                reasoning=f"Failed to parse response: {e}",
                raw_response=raw_response
            )


def progress_callback(event):
    """é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    if event.type == EventType.MATCH_START:
        item_a = event.data['item_a'][:40] + ('...' if len(event.data['item_a']) > 40 else '')
        item_b = event.data['item_b'][:40] + ('...' if len(event.data['item_b']) > 40 else '')
        print(f"  ğŸ”„ å¯¾æˆ¦é–‹å§‹: {item_a} vs {item_b}")
    elif event.type == EventType.MATCH_END:
        winner = event.data.get('winner', 'draw')
        print(f"  âœ… å¯¾æˆ¦çµ‚äº†: å‹è€… = {winner}")


async def test_basic_sorting():
    """åŸºæœ¬çš„ãªã‚½ãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ - çŸ­ã„æ–‡ç« ã®æ¯”è¼ƒ"""
    print("=" * 60)
    print("ãƒ†ã‚¹ãƒˆ1: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã®èª¬æ˜æ–‡ï¼ˆã‚ã‹ã‚Šã‚„ã™ã•ã§ã‚½ãƒ¼ãƒˆï¼‰")
    print("=" * 60)

    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        print("ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False

    provider = OpenAIProviderSync(
        api_key=api_key,
        model="gpt-4o-mini"
    )

    cache = MemoryCache()

    sorter = QualitativeSorter(
        provider=provider,
        criteria="åˆå¿ƒè€…ã«ã¨ã£ã¦ã®ã‚ã‹ã‚Šã‚„ã™ã•",
        elimination_count=2,
        comparison_rounds=2,
        max_concurrent_requests=3,
        cache=cache,
        on_progress=progress_callback,
    )

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã®èª¬æ˜
    items = [
        "Pythonã¯ã‚·ãƒ³ãƒ—ãƒ«ãªæ–‡æ³•ã§èª­ã¿ã‚„ã™ãã€åˆå¿ƒè€…ã«ã‚‚å­¦ã³ã‚„ã™ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™ã€‚",
        "Rustã¯æ‰€æœ‰æ¨©ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šãƒ¡ãƒ¢ãƒªå®‰å…¨æ€§ã‚’ä¿è¨¼ã™ã‚‹ã€é«˜æ€§èƒ½ãªã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™ã€‚",
        "JavaScriptã¯Webãƒ–ãƒ©ã‚¦ã‚¶ã§å‹•ä½œã—ã€å‹•çš„ãªå‹ä»˜ã‘ã‚’æŒã¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆè¨€èªã§ã™ã€‚",
        "Haskellã¯ç´”ç²‹é–¢æ•°å‹è¨€èªã§ã€é…å»¶è©•ä¾¡ã¨å¼·åŠ›ãªå‹ã‚·ã‚¹ãƒ†ãƒ ã‚’ç‰¹å¾´ã¨ã—ã¾ã™ã€‚",
    ]

    print("\nğŸ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿:")
    for i, item in enumerate(items, 1):
        print(f"  {i}. {item}")

    print("\nğŸ† ã‚½ãƒ¼ãƒˆå®Ÿè¡Œä¸­...")
    result = await sorter.sort(items)

    print("\nğŸ“Š çµæœ:")
    print("  é †ä½:")
    for rank, tier_items in result.rankings:
        for item in tier_items:
            print(f"    {rank}ä½: {item}")

    print(f"\n  çµ±è¨ˆæƒ…å ±:")
    print(f"    ç·ãƒãƒƒãƒæ•°: {result.statistics.total_matches}")
    print(f"    APIã‚³ãƒ¼ãƒ«æ•°: {result.statistics.total_api_calls}")
    print(f"    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {result.statistics.cache_hits}")
    print(f"    å®Ÿè¡Œæ™‚é–“: {result.statistics.elapsed_time:.2f}ç§’")

    return True


async def test_numeric_sorting():
    """æ•°å€¤ã®å¤§å°æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ãƒ†ã‚¹ãƒˆ2: æ•°å€¤ã®å¤§å°æ¯”è¼ƒï¼ˆå¤§ãã„é †ã«ã‚½ãƒ¼ãƒˆï¼‰")
    print("=" * 60)

    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return False

    provider = OpenAIProviderSync(
        api_key=api_key,
        model="gpt-4o-mini"
    )

    sorter = QualitativeSorter(
        provider=provider,
        criteria="æ•°å€¤ã¨ã—ã¦å¤§ãã„æ–¹ã‚’é¸ã‚“ã§ãã ã•ã„",
        elimination_count=2,
        comparison_rounds=2,
        max_concurrent_requests=3,
        on_progress=progress_callback,
    )

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: æ•°å€¤ï¼ˆæ­£ã—ã„é †åºãŒæ˜ç¢ºï¼‰
    items = ["100", "42", "7", "999", "256"]
    expected_order = ["999", "256", "100", "42", "7"]

    print("\nğŸ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿:", items)
    print("ğŸ“Œ æœŸå¾…ã•ã‚Œã‚‹é †åº:", expected_order)

    print("\nğŸ† ã‚½ãƒ¼ãƒˆå®Ÿè¡Œä¸­...")
    result = await sorter.sort(items)

    print("\nğŸ“Š çµæœ:")
    actual_order = []
    for rank, tier_items in result.rankings:
        for item in tier_items:
            actual_order.append(item)
            print(f"    {rank}ä½: {item}")

    # çµæœæ¤œè¨¼
    print(f"\n  å®Ÿéš›ã®é †åº: {actual_order}")
    print(f"  æœŸå¾…ã•ã‚Œã‚‹é †åº: {expected_order}")

    # ä¸Šä½3ã¤ãŒæ­£ã—ã„ã‹ç¢ºèª
    top3_correct = actual_order[:3] == expected_order[:3]
    print(f"  ä¸Šä½3ã¤ã®æ­£ç¢ºæ€§: {'âœ… æ­£ã—ã„' if top3_correct else 'âŒ ç•°ãªã‚‹'}")

    return True


async def test_character_strength():
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å¼·ã•æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ãƒ†ã‚¹ãƒˆ3: æ¶ç©ºã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®æˆ¦é—˜åŠ›ï¼ˆå¼·ã•é †ã«ã‚½ãƒ¼ãƒˆï¼‰")
    print("=" * 60)

    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return False

    provider = OpenAIProviderSync(
        api_key=api_key,
        model="gpt-4o-mini"
    )

    sorter = QualitativeSorter(
        provider=provider,
        criteria="æˆ¦é—˜èƒ½åŠ›ã‚„å¼·ã•ã®è¦³ç‚¹ã§ã€ã‚ˆã‚Šå¼·ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚ä¸€èˆ¬çš„ãªèªè­˜ã‚„ä½œä¸­ã®æå†™ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚",
        elimination_count=2,
        comparison_rounds=2,
        max_concurrent_requests=3,
        on_progress=progress_callback,
    )

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: æœ‰åãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼
    items = [
        "å­«æ‚Ÿç©ºï¼ˆãƒ‰ãƒ©ã‚´ãƒ³ãƒœãƒ¼ãƒ«ï¼‰",
        "ãƒ«ãƒ•ã‚£ï¼ˆãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹ï¼‰",
        "ãƒŠãƒ«ãƒˆï¼ˆNARUTOï¼‰",
        "ä¸€èˆ¬çš„ãªæˆäººç”·æ€§",
    ]

    print("\nğŸ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿:")
    for item in items:
        print(f"  - {item}")

    print("\nğŸ† ã‚½ãƒ¼ãƒˆå®Ÿè¡Œä¸­...")
    result = await sorter.sort(items)

    print("\nğŸ“Š çµæœ:")
    for rank, tier_items in result.rankings:
        for item in tier_items:
            print(f"    {rank}ä½: {item}")

    print(f"\n  çµ±è¨ˆæƒ…å ±:")
    print(f"    ç·ãƒãƒƒãƒæ•°: {result.statistics.total_matches}")
    print(f"    APIã‚³ãƒ¼ãƒ«æ•°: {result.statistics.total_api_calls}")
    print(f"    å®Ÿè¡Œæ™‚é–“: {result.statistics.elapsed_time:.2f}ç§’")

    return True


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸš€ GPTçµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)
    print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: gpt-4o-mini")
    print("=" * 60)

    success = True

    try:
        # ãƒ†ã‚¹ãƒˆ1: åŸºæœ¬çš„ãªã‚½ãƒ¼ãƒˆ
        if not await test_basic_sorting():
            success = False

        # ãƒ†ã‚¹ãƒˆ2: æ•°å€¤æ¯”è¼ƒ
        if not await test_numeric_sorting():
            success = False

        # ãƒ†ã‚¹ãƒˆ3: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¼·ã•
        if not await test_character_strength():
            success = False

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        success = False

    print("\n" + "=" * 60)
    if success:
        print("âœ… å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸ")
    else:
        print("âŒ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
    print("=" * 60)

    return success


if __name__ == "__main__":
    asyncio.run(main())
